{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SoccerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/yjing17/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading ./tracking/train.zip...: : 9.58GiB [09:52, 16.2MiB/s]                           \n",
      "Downloading ./tracking/test.zip...: : 8.71GiB [09:13, 15.7MiB/s]                           \n",
      "Downloading ./tracking/challenge.zip...: : 11.0GiB [11:50, 15.5MiB/s]                           \n"
     ]
    }
   ],
   "source": [
    "from SoccerNet.Downloader import SoccerNetDownloader\n",
    "mySoccerNetDownloader = SoccerNetDownloader(LocalDirectory=\"./\")\n",
    "mySoccerNetDownloader.downloadDataTask(task=\"tracking\", split=[\"train\",\"test\",\"challenge\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "unzip -q tracking/train.zip -d ./Dataset/tracking\n",
    "unzip -q tracking/test.zip -d ./Dataset/tracking\n",
    "unzip -q tracking/challenge.zip -d ./Dataset/tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate labels for dataset\n",
    "\n",
    "#### output: txt file including below information for each image:\n",
    "    \n",
    "    class id(0), Track ID(tid), normalized x coordinate of the bounding box center, normalized y coordinate of the bounding box center, normalized height of the bounding box, normalized width of the bounding box. \n",
    "    \n",
    "    (normalization made relative to the frame width/height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences in ./dataset/images/train: 100%|██████████| 57/57 [00:05<00:00, 10.39it/s]\n",
      "Writing labels: 100%|██████████| 42750/42750 [03:39<00:00, 194.79it/s]\n",
      "Processing sequences in ./dataset/images/test: 100%|██████████| 49/49 [00:04<00:00, 10.19it/s]\n",
      "Writing labels: 100%|██████████| 36750/36750 [03:22<00:00, 181.78it/s]\n"
     ]
    }
   ],
   "source": [
    "def mkdirs(d):\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "\n",
    "seq_roots = ['./dataset/images/train', './dataset/images/test']\n",
    "label_roots = ['./dataset/labels_with_ids/train', './dataset/labels_with_ids/test']\n",
    "\n",
    "for seq_root, label_root in zip(seq_roots, label_roots):\n",
    "    mkdirs(label_root)\n",
    "    seqs = [s for s in os.listdir(seq_root)]\n",
    "\n",
    "    tid_curr = 0\n",
    "    tid_last = -1\n",
    "\n",
    "    output = {}\n",
    "\n",
    "    for seq in tqdm(seqs, desc=f\"Processing sequences in {seq_root}\"):\n",
    "        seq_info = open(os.path.join(seq_root, seq, 'seqinfo.ini')).read()\n",
    "        seq_width = int(seq_info[seq_info.find('imWidth=') + 8:seq_info.find(\n",
    "            '\\nimHeight')])\n",
    "        seq_height = int(seq_info[seq_info.find('imHeight=') + 9:seq_info.find(\n",
    "            '\\nimExt')])\n",
    "\n",
    "        gt_txt = os.path.join(seq_root, seq, 'gt', 'gt.txt')\n",
    "        gt = np.loadtxt(gt_txt, dtype=np.float64, delimiter=',')\n",
    "\n",
    "        seq_label_root = os.path.join(label_root, seq, 'img1')\n",
    "        mkdirs(seq_label_root)\n",
    "        \n",
    "        # Frame ID, Track ID, left coor X, top coor Y, width W, height H, Score, Unused, Unused, Unused\n",
    "        for fid, tid, x, y, w, h, score, label, _, _ in tqdm(gt, desc=f\"Processing GT for {seq}\", leave=False):\n",
    "            if score == 0 or not label == -1.0:\n",
    "                continue\n",
    "\n",
    "            fid = int(fid)\n",
    "            tid = int(tid)\n",
    "            if not tid == tid_last:\n",
    "                tid_curr += 1\n",
    "                tid_last = tid\n",
    "            # bounding box center coordinates\n",
    "            x += w / 2 \n",
    "            y += h / 2\n",
    "            label_fpath = os.path.join(seq_label_root, '{:06d}.txt'.format(fid))\n",
    "            # class id(0), tid\n",
    "            # normalized coordinate of the bounding box center (relative to the frame width)\n",
    "            # normalized height/width of the bounding box (relative to the frame width).\n",
    "            label_str = '0 {:d} {:.6f} {:.6f} {:.6f} {:.6f}\\n'.format(\n",
    "                tid_curr, x / seq_width, y / seq_height, w / seq_width,\n",
    "                h / seq_height)\n",
    "            if not label_fpath in output:\n",
    "                output[label_fpath] = []\n",
    "            output[label_fpath].append(label_str)\n",
    "\n",
    "    for key in tqdm(output, desc=\"Writing labels\"):\n",
    "        with open(key, 'w') as f:\n",
    "            lines = output[key]\n",
    "            for line in lines:\n",
    "                f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate images list for train/test\n",
    "#### output:txt file containg path to all images in train/test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_image_list(dataPath, datType, image_list_root='./dataset/image_lists'):\n",
    "    if not os.path.exists(image_list_root):\n",
    "        os.mkdir(image_list_root)\n",
    "    inputPath = f'{dataPath}/images/{datType}'\n",
    "    pathList = glob.glob(inputPath + '/*')\n",
    "    pathList = sorted(pathList)\n",
    "    allImageList = []\n",
    "    for pathSingle in pathList:\n",
    "        imgList = sorted(glob.glob(os.path.join(pathSingle, 'img1', '*.jpg')))\n",
    "        for imgPath in imgList:\n",
    "            allImageList.append(imgPath)\n",
    "    image_list_fname = os.path.join(image_list_root, f'{dataPath}.{datType}')\n",
    "    with open(image_list_fname, 'w') as image_list_file:\n",
    "        allImageListStr = str.join('\\n', allImageList)\n",
    "        image_list_file.write(allImageListStr)\n",
    "\n",
    "gen_image_list('dataset', 'train')\n",
    "gen_image_list('dataset', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converts a dataset with video frames and ground truth annotations into COCO-style JSON format.\n",
    "#### output: JSON files\n",
    "\n",
    "    images: Metadata about the images in the dataset.\n",
    "\n",
    "    annotations: Bounding box annotations.\n",
    "\n",
    "    videos: Metadata about the video sequences.\n",
    "\n",
    "    categories: Information about the object categories (in this case, pedestrians).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNMOT-060: 750 images\n",
      "750 ann images\n",
      "26 26\n",
      "SNMOT-061: 750 images\n",
      "750 ann images\n",
      "53 27\n",
      "SNMOT-062: 750 images\n",
      "750 ann images\n",
      "77 24\n",
      "SNMOT-063: 750 images\n",
      "750 ann images\n",
      "102 25\n",
      "SNMOT-064: 750 images\n",
      "750 ann images\n",
      "126 24\n",
      "SNMOT-065: 750 images\n",
      "750 ann images\n",
      "152 26\n",
      "SNMOT-066: 750 images\n",
      "750 ann images\n",
      "177 25\n",
      "SNMOT-067: 750 images\n",
      "750 ann images\n",
      "203 26\n",
      "SNMOT-068: 750 images\n",
      "750 ann images\n",
      "227 24\n",
      "SNMOT-069: 750 images\n",
      "750 ann images\n",
      "251 24\n",
      "SNMOT-070: 750 images\n",
      "750 ann images\n",
      "276 25\n",
      "SNMOT-071: 750 images\n",
      "750 ann images\n",
      "298 22\n",
      "SNMOT-072: 750 images\n",
      "750 ann images\n",
      "322 24\n",
      "SNMOT-073: 750 images\n",
      "750 ann images\n",
      "347 25\n",
      "SNMOT-074: 750 images\n",
      "750 ann images\n",
      "372 25\n",
      "SNMOT-075: 750 images\n",
      "750 ann images\n",
      "396 24\n",
      "SNMOT-076: 750 images\n",
      "750 ann images\n",
      "425 29\n",
      "SNMOT-077: 750 images\n",
      "750 ann images\n",
      "449 24\n",
      "SNMOT-097: 750 images\n",
      "750 ann images\n",
      "471 22\n",
      "SNMOT-098: 750 images\n",
      "750 ann images\n",
      "497 26\n",
      "SNMOT-099: 750 images\n",
      "750 ann images\n",
      "522 25\n",
      "SNMOT-100: 750 images\n",
      "750 ann images\n",
      "548 26\n",
      "SNMOT-101: 750 images\n",
      "750 ann images\n",
      "573 25\n",
      "SNMOT-102: 750 images\n",
      "750 ann images\n",
      "599 26\n",
      "SNMOT-103: 750 images\n",
      "750 ann images\n",
      "623 24\n",
      "SNMOT-104: 750 images\n",
      "750 ann images\n",
      "646 23\n",
      "SNMOT-105: 750 images\n",
      "750 ann images\n",
      "672 26\n",
      "SNMOT-106: 750 images\n",
      "750 ann images\n",
      "697 25\n",
      "SNMOT-107: 750 images\n",
      "750 ann images\n",
      "722 25\n",
      "SNMOT-108: 750 images\n",
      "750 ann images\n",
      "748 26\n",
      "SNMOT-109: 750 images\n",
      "750 ann images\n",
      "772 24\n",
      "SNMOT-110: 750 images\n",
      "750 ann images\n",
      "799 27\n",
      "SNMOT-111: 750 images\n",
      "750 ann images\n",
      "827 28\n",
      "SNMOT-112: 750 images\n",
      "750 ann images\n",
      "853 26\n",
      "SNMOT-113: 750 images\n",
      "750 ann images\n",
      "884 31\n",
      "SNMOT-114: 750 images\n",
      "750 ann images\n",
      "908 24\n",
      "SNMOT-115: 750 images\n",
      "750 ann images\n",
      "931 23\n",
      "SNMOT-151: 750 images\n",
      "750 ann images\n",
      "956 25\n",
      "SNMOT-152: 750 images\n",
      "750 ann images\n",
      "978 22\n",
      "SNMOT-153: 750 images\n",
      "750 ann images\n",
      "1006 28\n",
      "SNMOT-154: 750 images\n",
      "750 ann images\n",
      "1030 24\n",
      "SNMOT-155: 750 images\n",
      "750 ann images\n",
      "1054 24\n",
      "SNMOT-156: 750 images\n",
      "750 ann images\n",
      "1078 24\n",
      "SNMOT-157: 750 images\n",
      "750 ann images\n",
      "1102 24\n",
      "SNMOT-158: 750 images\n",
      "750 ann images\n",
      "1128 26\n",
      "SNMOT-159: 750 images\n",
      "750 ann images\n",
      "1151 23\n",
      "SNMOT-160: 750 images\n",
      "750 ann images\n",
      "1176 25\n",
      "SNMOT-161: 750 images\n",
      "750 ann images\n",
      "1201 25\n",
      "SNMOT-162: 750 images\n",
      "750 ann images\n",
      "1226 25\n",
      "SNMOT-163: 750 images\n",
      "750 ann images\n",
      "1251 25\n",
      "SNMOT-164: 750 images\n",
      "750 ann images\n",
      "1276 25\n",
      "SNMOT-165: 750 images\n",
      "750 ann images\n",
      "1302 26\n",
      "SNMOT-166: 750 images\n",
      "750 ann images\n",
      "1328 26\n",
      "SNMOT-167: 750 images\n",
      "750 ann images\n",
      "1353 25\n",
      "SNMOT-168: 750 images\n",
      "750 ann images\n",
      "1376 23\n",
      "SNMOT-169: 750 images\n",
      "750 ann images\n",
      "1402 26\n",
      "SNMOT-170: 750 images\n",
      "750 ann images\n",
      "1427 25\n",
      "loaded train for 42750 images and 733002 samples\n",
      "SNMOT-116: 750 images\n",
      "750 ann images\n",
      "27 27\n",
      "SNMOT-117: 750 images\n",
      "750 ann images\n",
      "58 31\n",
      "SNMOT-118: 750 images\n",
      "750 ann images\n",
      "83 25\n",
      "SNMOT-119: 750 images\n",
      "750 ann images\n",
      "109 26\n",
      "SNMOT-120: 750 images\n",
      "750 ann images\n",
      "136 27\n",
      "SNMOT-121: 750 images\n",
      "750 ann images\n",
      "159 23\n",
      "SNMOT-122: 750 images\n",
      "750 ann images\n",
      "185 26\n",
      "SNMOT-123: 750 images\n",
      "750 ann images\n",
      "210 25\n",
      "SNMOT-124: 750 images\n",
      "750 ann images\n",
      "235 25\n",
      "SNMOT-125: 750 images\n",
      "750 ann images\n",
      "261 26\n",
      "SNMOT-126: 750 images\n",
      "750 ann images\n",
      "286 25\n",
      "SNMOT-127: 750 images\n",
      "750 ann images\n",
      "308 22\n",
      "SNMOT-128: 750 images\n",
      "750 ann images\n",
      "332 24\n",
      "SNMOT-129: 750 images\n",
      "750 ann images\n",
      "357 25\n",
      "SNMOT-130: 750 images\n",
      "750 ann images\n",
      "378 21\n",
      "SNMOT-131: 750 images\n",
      "750 ann images\n",
      "401 23\n",
      "SNMOT-132: 750 images\n",
      "750 ann images\n",
      "426 25\n",
      "SNMOT-133: 750 images\n",
      "750 ann images\n",
      "455 29\n",
      "SNMOT-134: 750 images\n",
      "750 ann images\n",
      "478 23\n",
      "SNMOT-135: 750 images\n",
      "750 ann images\n",
      "502 24\n",
      "SNMOT-136: 750 images\n",
      "750 ann images\n",
      "527 25\n",
      "SNMOT-137: 750 images\n",
      "750 ann images\n",
      "552 25\n",
      "SNMOT-138: 750 images\n",
      "750 ann images\n",
      "577 25\n",
      "SNMOT-139: 750 images\n",
      "750 ann images\n",
      "598 21\n",
      "SNMOT-140: 750 images\n",
      "750 ann images\n",
      "621 23\n",
      "SNMOT-141: 750 images\n",
      "750 ann images\n",
      "645 24\n",
      "SNMOT-142: 750 images\n",
      "750 ann images\n",
      "670 25\n",
      "SNMOT-143: 750 images\n",
      "750 ann images\n",
      "694 24\n",
      "SNMOT-144: 750 images\n",
      "750 ann images\n",
      "719 25\n",
      "SNMOT-145: 750 images\n",
      "750 ann images\n",
      "744 25\n",
      "SNMOT-146: 750 images\n",
      "750 ann images\n",
      "766 22\n",
      "SNMOT-147: 750 images\n",
      "750 ann images\n",
      "793 27\n",
      "SNMOT-148: 750 images\n",
      "750 ann images\n",
      "816 23\n",
      "SNMOT-149: 750 images\n",
      "750 ann images\n",
      "840 24\n",
      "SNMOT-150: 750 images\n",
      "750 ann images\n",
      "869 29\n",
      "SNMOT-187: 750 images\n",
      "750 ann images\n",
      "893 24\n",
      "SNMOT-188: 750 images\n",
      "750 ann images\n",
      "920 27\n",
      "SNMOT-189: 750 images\n",
      "750 ann images\n",
      "945 25\n",
      "SNMOT-190: 750 images\n",
      "750 ann images\n",
      "969 24\n",
      "SNMOT-191: 750 images\n",
      "750 ann images\n",
      "993 24\n",
      "SNMOT-192: 750 images\n",
      "750 ann images\n",
      "1019 26\n",
      "SNMOT-193: 750 images\n",
      "750 ann images\n",
      "1045 26\n",
      "SNMOT-194: 750 images\n",
      "750 ann images\n",
      "1069 24\n",
      "SNMOT-195: 750 images\n",
      "750 ann images\n",
      "1091 22\n",
      "SNMOT-196: 750 images\n",
      "750 ann images\n",
      "1115 24\n",
      "SNMOT-197: 750 images\n",
      "750 ann images\n",
      "1139 24\n",
      "SNMOT-198: 750 images\n",
      "750 ann images\n",
      "1166 27\n",
      "SNMOT-199: 750 images\n",
      "750 ann images\n",
      "1191 25\n",
      "SNMOT-200: 750 images\n",
      "750 ann images\n",
      "1211 20\n",
      "loaded test for 36750 images and 564547 samples\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'dataset/images'\n",
    "OUT_PATH = 'dataset/annotations'\n",
    "SPLITS = ['train', 'test']\n",
    "\n",
    "if not os.path.exists(OUT_PATH):\n",
    "    os.makedirs(OUT_PATH)\n",
    "\n",
    "for split in SPLITS:\n",
    "    data_path = os.path.join(DATA_PATH, split)\n",
    "    out_path = os.path.join(OUT_PATH, '{}.json'.format(split))\n",
    "    out = {'images': [], 'annotations': [], 'videos': [],\n",
    "            'categories': [{'id': 1, 'name': 'pedestrian'}]}\n",
    "    seqs = os.listdir(data_path)\n",
    "    image_cnt = 0\n",
    "    ann_cnt = 0\n",
    "    video_cnt = 0\n",
    "    tid_curr = 0\n",
    "    tid_last = -1\n",
    "    for seq in sorted(seqs):\n",
    "        if '.DS_Store' in seq:\n",
    "            continue\n",
    "        video_cnt += 1  # video sequence number.\n",
    "        out['videos'].append({'id': video_cnt, 'file_name': seq})\n",
    "        seq_path = os.path.join(data_path, seq)\n",
    "        img_path = os.path.join(seq_path, 'img1')\n",
    "        ann_path = os.path.join(seq_path, 'gt/gt.txt')\n",
    "        images = os.listdir(img_path)\n",
    "        num_images = len([image for image in images if 'jpg' in image])\n",
    "        image_range = [0, num_images - 1]\n",
    "\n",
    "        for i in range(num_images):\n",
    "            if i < image_range[0] or i > image_range[1]:\n",
    "                continue\n",
    "            img = cv2.imread(os.path.join(data_path, '{}/img1/{:06d}.jpg'.format(seq, i + 1)))\n",
    "            height, width = img.shape[:2]\n",
    "            image_info = {'file_name': '{}/img1/{:06d}.jpg'.format(seq, i + 1),  # image name.\n",
    "                            'id': image_cnt + i + 1,  # image number in the entire training set.\n",
    "                            'frame_id': i + 1 - image_range[0],  # image number in the video sequence, starting from 1.\n",
    "                            'prev_image_id': image_cnt + i if i > 0 else -1,  # image number in the entire training set.\n",
    "                            'next_image_id': image_cnt + i + 2 if i < num_images - 1 else -1,\n",
    "                            'video_id': video_cnt,\n",
    "                            'height': height, 'width': width}\n",
    "            out['images'].append(image_info)\n",
    "        print('{}: {} images'.format(seq, num_images))\n",
    "        det_path = os.path.join(seq_path, 'det/det.txt')\n",
    "        anns = np.loadtxt(ann_path, dtype=np.float32, delimiter=',')\n",
    "        dets = np.loadtxt(det_path, dtype=np.float32, delimiter=',')\n",
    "        print('{} ann images'.format(int(anns[:, 0].max())))\n",
    "        for i in range(anns.shape[0]):\n",
    "            frame_id = int(anns[i][0])\n",
    "            if frame_id - 1 < image_range[0] or frame_id - 1 > image_range[1]:\n",
    "                continue\n",
    "            track_id = int(anns[i][1])\n",
    "            cat_id = int(anns[i][7])\n",
    "            ann_cnt += 1\n",
    "            category_id = 1\n",
    "            ann = {'id': ann_cnt,\n",
    "                    'category_id': category_id,\n",
    "                    'image_id': image_cnt + frame_id,\n",
    "                    'track_id': tid_curr,\n",
    "                    'bbox': anns[i][2:6].tolist(),\n",
    "                    'conf': float(anns[i][6]),\n",
    "                    'iscrowd': 0,\n",
    "                    'area': float(anns[i][4] * anns[i][5])}\n",
    "            out['annotations'].append(ann)\n",
    "        image_cnt += num_images\n",
    "        print(tid_curr, tid_last)\n",
    "    print('loaded {} for {} images and {} samples'.format(split, len(out['images']), len(out['annotations'])))\n",
    "    json.dump(out, open(out_path, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter det files\n",
    "#### out: txt contains only useful fields in det files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    }
   ],
   "source": [
    "seq_roots = ['./dataset/images/train', './dataset/images/test']\n",
    "det_roots = ['./dataset/det_files/train', './dataset/det_files/test']\n",
    "\n",
    "for seq_root, det_root in zip(seq_roots, det_roots):\n",
    "    mkdirs(det_root)\n",
    "    seqs = [s for s in os.listdir(seq_root)]\n",
    "    for seq in tqdm(seqs, desc=f\"Processing det for {seq}\", leave=False):\n",
    "        src_det_txt = os.path.join(seq_root, seq, 'det', 'det.txt')\n",
    "        src_det = np.loadtxt(src_det_txt, dtype=np.float64, delimiter=',')\n",
    "        #only extract 7 items per row: [frame_id],[x0],[y0],[w],[h],[score],[class_id]\n",
    "        dst_det = src_det[:, [0,2,3,4,5,6,7]]\n",
    "        dst_det_txt = os.path.join(det_root, f'{seq}.txt')\n",
    "        np.savetxt(dst_det_txt, dst_det, fmt='%d', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zip ground truth files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def zipdir(path, ziph):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('gt.txt') or file.endswith('seqinfo.ini'):\n",
    "                ziph.write(os.path.join(root, file), \n",
    "                        os.path.relpath(os.path.join(root, file), \n",
    "                                        os.path.join(path, '..')))\n",
    "\n",
    "with zipfile.ZipFile('gt.zip', 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    zipdir('./dataset/images/test', zipf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
